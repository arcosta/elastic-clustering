{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import httpx\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import asyncio\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#!{sys.executable} -m pip install --upgrade pip\n",
    "!{sys.executable} -m pip install --user matplotlib\n",
    "#!{sys.executable} -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vector_path=pickle.load('C:\\PRojetos\\STF-Digital\\IA\\agrupament\\data\\vetores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 93.8 ms\n",
      "Wall time: 142 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:4: ResourceWarning: unclosed file <_io.BufferedReader name='..\\\\..\\\\agrupamento\\\\data\\\\vetores\\\\vetores_1000_limpeza_basica_clean.pkl'>\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p=Path('..','..','agrupamento','data','vetores')\n",
    "vector = None\n",
    "for f in p.glob('*'):\n",
    "    vector = pickle.load(f.open(mode='rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de vetores 22868\n",
      "Tamanho do vetor 300\n"
     ]
    }
   ],
   "source": [
    "#glob\n",
    "v_qtd = len(vector)\n",
    "print('Quantidade de vetores', v_qtd)\n",
    "v_len = len(vector[0])\n",
    "print('Tamanho do vetor', v_len)\n",
    "query_vector = vector[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definição do Indice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "index = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "  \"mappings\": {\n",
    "    \"properties\": {\n",
    "      \"my_vector\": {\n",
    "        \"type\": \"dense_vector\",\n",
    "        \"dims\": v_len,\n",
    "        \"index\": \"true\",\n",
    "        \"similarity\": \"dot_product\"\n",
    "      },\n",
    "      \"seq_documento\" : {\n",
    "        \"type\" : \"keyword\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "username='elastic'\n",
    "password='password'\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "index = json.dumps(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialização do elastic localmente\n",
    "\n",
    "O Elastic recomenda cria uma rede antes\n",
    "\n",
    "```docker network create pocnet```\n",
    "\n",
    "Para iniciar o container\n",
    "\n",
    "```docker run -d --name elasticsearch --net pocnet -p 9200:9200 -p 9300:9300 -e \"ELASTIC_PASSWORD=password\" -e \"discovery.type=single-node\" elasticsearch:8.4.2```\n",
    "\n",
    "Iniciei também o ElasticHQ para acompannhar as estatísticas do ambiente com o comando\n",
    "\n",
    "```docker run -d --name elastichq --net pocnet --rm -p 5000:5000 -e HQ_VERIFY_CERTS=False -e HQ_ENABLE_SSL=False -e HQ_DEBUG=True elastichq/elasticsearch-hq```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Criação do íncide poc_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aurelio.costa\\AppData\\Roaming\\Python\\Python39\\site-packages\\urllib3\\connectionpool.py:1043: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{'X-elastic-product': 'Elasticsearch', 'content-type': 'application/json', 'content-length': '68'}\n",
      "528 ms ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "\n",
    "req = requests.request(\n",
    "    'PUT', \n",
    "    'https://localhost:9200/poc_index', \n",
    "    auth=(username, password), \n",
    "    data=index,\n",
    "    verify=False, \n",
    "    headers=headers\n",
    ")\n",
    "print(req.status_code)\n",
    "print(req.headers)\n",
    "#print(req.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testando a indexação de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: total: 8min 35s\n",
      "Wall time: 17min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for idx, doc in enumerate(vector):\n",
    "    unit_vector = doc / np.linalg.norm(doc)\n",
    "    #unit_vector = unit_vector + np.abs(min(unit_vector))\n",
    "    resp = requests.request(\n",
    "        'POST', \n",
    "        'https://localhost:9200/poc_index/_doc',\n",
    "        auth=(username, password), \n",
    "        data=json.dumps({'my_vector': unit_vector.tolist(), 'seq_documento': idx}),\n",
    "        verify=False, \n",
    "        headers=headers\n",
    "    )\n",
    "    #print(idx,resp.status_code, end=' | ')\n",
    "    #print(resp.headers)\n",
    "    #print(resp.content)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v0 = random.sample(vector, 1)[0]\n",
    "v=v0/np.linalg.norm(v0)\n",
    "query_vector = v #(v+ np.abs(min(v))).tolist()\n",
    "print('Norma de v0', np.linalg.norm(v0))\n",
    "print('Norma de v (deve ser 1)', np.linalg.norm(v))\n",
    "print('Norma de query_vector ', np.linalg.norm(query_vector))\n",
    "for pair in zip(v0, v):\n",
    "    print(f'{pair[0]:>20}|{pair[1]:<20}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deletando o indice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "resp = requests.request(\n",
    "    'DELETE', \n",
    "    'https://localhost:9200/poc_index',\n",
    "    auth=(username, password), \n",
    "    verify=False, \n",
    "    headers=headers\n",
    ")\n",
    "print(resp.status_code)\n",
    "print(resp.headers)\n",
    "#print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste de consultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\"error\":{\"root_cause\":[{\"type\":\"illegal_argument_exception\",\"reason\":\"script_score script returned an invalid score [-1.2817156] for doc [9]. Must be a non-negative score!\"}],\"type\":\"search_phase_execution_exception\",\"reason\":\"all shards failed\",\"phase\":\"query\",\"grouped\":true,\"failed_shards\":[{\"shard\":0,\"index\":\"poc_index\",\"node\":\"D-ECyJNjT3mpmGefcf3HPA\",\"reason\":{\"type\":\"illegal_argument_exception\",\"reason\":\"script_score script returned an invalid score [-1.2817156] for doc [9]. Must be a non-negative score!\"}}],\"caused_by\":{\"type\":\"illegal_argument_exception\",\"reason\":\"script_score script returned an invalid score [-1.2817156] for doc [9]. Must be a non-negative score!\",\"caused_by\":{\"type\":\"illegal_argument_exception\",\"reason\":\"script_score script returned an invalid score [-1.2817156] for doc [9]. Must be a non-negative score!\"}}},\"status\":400}'\n"
     ]
    }
   ],
   "source": [
    "# Consulta o campo my_vector usando dotProduct com o parametro query_vector\n",
    "query = {\n",
    "    \"query\": {\n",
    "      \"script_score\": {\n",
    "        \"query\": {\"match_all\": {}},\n",
    "        \"script\": {\n",
    "          \"source\": \"dotProduct(params.query_vector, 'my_vector') + 1.0\",\n",
    "          \"params\": {\"query_vector\": query_vector.tolist()}\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Transforma o dicionario da consulta em um json para enviar via HTTP\n",
    "query = json.dumps(query)\n",
    "\n",
    "resp = requests.request(\n",
    "    'GET', \n",
    "    'https://localhost:9200/poc_index/_search',\n",
    "    data=query,\n",
    "    auth=(username, password), \n",
    "    verify=False, \n",
    "    headers=headers\n",
    ")\n",
    "print(resp.content)\n",
    "\n",
    "#content = json.loads(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busca usando o a API kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KeyError\n",
      "{'error': {'root_cause': [{'type': 'query_shard_exception', 'reason': 'failed to create query: The [dot_product] similarity can only be used with unit-length vectors. Preview of invalid vector: [4.1922255, -3.3499126, 2.2107997, -1.570513, 1.9997157, ...]', 'index_uuid': 'ruoOS1ftSpKtwNu-oG-UAg', 'index': 'poc_index'}], 'type': 'search_phase_execution_exception', 'reason': 'all shards failed', 'phase': 'dfs', 'grouped': True, 'failed_shards': [{'shard': 0, 'index': 'poc_index', 'node': 'D-ECyJNjT3mpmGefcf3HPA', 'reason': {'type': 'query_shard_exception', 'reason': 'failed to create query: The [dot_product] similarity can only be used with unit-length vectors. Preview of invalid vector: [4.1922255, -3.3499126, 2.2107997, -1.570513, 1.9997157, ...]', 'index_uuid': 'ruoOS1ftSpKtwNu-oG-UAg', 'index': 'poc_index', 'caused_by': {'type': 'illegal_argument_exception', 'reason': 'The [dot_product] similarity can only be used with unit-length vectors. Preview of invalid vector: [4.1922255, -3.3499126, 2.2107997, -1.570513, 1.9997157, ...]'}}}]}, 'status': 400}\n",
      "set()\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 71.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "def retorna_similares(vector, k, threshold=0.9, candidates=200):\n",
    "    knn_query = {\n",
    "        \"knn\": {\n",
    "            \"field\": \"my_vector\",\n",
    "            \"query_vector\": vector,\n",
    "            \"k\": k,\n",
    "            \"num_candidates\": candidates\n",
    "        },\n",
    "        \"size\": k,\n",
    "        \"fields\": ['seq_documento']\n",
    "    }\n",
    "\n",
    "    resp = requests.request(\n",
    "        'GET', \n",
    "        'https://localhost:9200/poc_index/_search',\n",
    "        data=json.dumps(knn_query),\n",
    "        auth=(username, password), \n",
    "        verify=False, \n",
    "        headers=headers\n",
    "    )\n",
    "\n",
    "    content = json.loads(resp.content)\n",
    "    ret = set()\n",
    "    try:\n",
    "        time_taken=content['took']\n",
    "        hits_count=len(content['hits']['hits'])\n",
    "\n",
    "        #print(f'Levou {time_taken}ms o melhor score de {hits_count}')\n",
    "        \n",
    "        for hit in content['hits']['hits']:\n",
    "            score=hit[\"_score\"]\n",
    "            seq_documento=hit[\"fields\"][\"seq_documento\"][0]\n",
    "            if float(score) < threshold:\n",
    "                break\n",
    "            #print(f'{seq_documento} - score {score}')\n",
    "            ret.add(seq_documento)\n",
    "    except KeyError as err:\n",
    "        print(\"KeyError\")\n",
    "        print(content)\n",
    "    return ret\n",
    "similares = retorna_similares(query_vector.tolist(), k=50)\n",
    "print(similares)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusterizando os documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pega a quantidade de documentos no indice\n",
    "resp = requests.request(\n",
    "    'GET', \n",
    "    'https://localhost:9200/poc_index/_count',\n",
    "    auth=(username, password), \n",
    "    verify=False, \n",
    "    headers=headers\n",
    ")     \n",
    "content = json.loads(resp.content)\n",
    "num_docs = content['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retorna_similares' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:25\u001b[0m\n",
      "File \u001b[1;32m<timed exec>:20\u001b[0m, in \u001b[0;36mcria_clusters\u001b[1;34m(doc)\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'retorna_similares' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clusters=dict() # dicionario no formato cluster[seq_documento]= [conjunto de similares]\n",
    "\n",
    "def cria_clusters(doc):\n",
    "    query_seq_documento = {\n",
    "       \"_source\": \"my_vector\"\n",
    "    }\n",
    "    \n",
    "    with httpx.Client(verify=False) as client:\n",
    "        resp = client.request(\n",
    "            'GET', \n",
    "            'https://localhost:9200/poc_index/_search/?q=seq_documento:'+str(doc),\n",
    "            auth=(username, password), \n",
    "            data=json.dumps(query_seq_documento),\n",
    "#            verify=False, \n",
    "            headers=headers\n",
    "        )     \n",
    "    content = json.loads(resp.content)\n",
    "    vec=content['hits']['hits'][0]['_source']['my_vector']\n",
    "    \n",
    "    similares = retorna_similares(vec, k=50)\n",
    "    return similares\n",
    "\n",
    "\n",
    "for doc in range(num_docs):\n",
    "    clusters[doc] = cria_clusters(doc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(clusters[100])\n",
    "for k1,v1 in clusters.items():\n",
    "    for k2,v2 in clusters.items():\n",
    "        if v1 == v2 and k1 != k2:\n",
    "            print(\"Similaries\", k1, k2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#from collections import defaultdict\n",
    "#hist = defaultdict(lambda x: 0)\n",
    "#hist = dict()\n",
    "hist = list()\n",
    "for k,v in clusters.items():\n",
    "    hist.append(len(await v))\n",
    "\n",
    "hist.sort(reverse=True)\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, bins, patches = plt.hist(hist, 50)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist[:2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
